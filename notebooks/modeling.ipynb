{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling notebook\n",
    "\n",
    "1. This notebook implements 3 models\n",
    "    *   A lineal regression model as baseline\n",
    "    *   A tree-based model as potential candidate and also as a pipeline to do Feature importance\n",
    "    *   A MLP to use as the main regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test datasets preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1075/584058149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_value_homes['cluster'] = kmeans.fit_predict(high_value_homes[['latitude', 'longitude']])\n",
      "/tmp/ipykernel_1075/584058149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_value_homes['cluster'] = kmeans.fit_predict(high_value_homes[['latitude', 'longitude']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14448, 25)\n",
      "(6192, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.centroids = None\n",
    "\n",
    "\n",
    "    def __compute_distance(self, point, centroid):\n",
    "        return np.sqrt((point[0] - centroid[0])**2 + (point[1] - centroid[1])**2)\n",
    "\n",
    "    def __distance_to_closest_centroid(self, row):\n",
    "        distances = [self.__compute_distance([row['latitude'], row['longitude']], centroid) for centroid in self.centroids]\n",
    "        return min(distances)\n",
    "\n",
    "    def __get_distance_to_high_value_area(self, X):\n",
    "        if self.centroids is None:\n",
    "            raise ValueError('Fit the model first before transforming the data')\n",
    "        \n",
    "        X['distance_to_high_value_area'] = X.apply(lambda row: self.__distance_to_closest_centroid(row), axis=1)\n",
    "        return X\n",
    "\n",
    "    # Fit the KMeans clustering model for the distance to high value area feature\n",
    "    def fit(self, X, y=None, num_clusters=2):\n",
    "        threshold = X['median_house_value'].quantile(0.80)\n",
    "        high_value_homes = X[X['median_house_value'] > threshold]\n",
    "\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=10)\n",
    "        high_value_homes['cluster'] = kmeans.fit_predict(high_value_homes[['latitude', 'longitude']])\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['bedrooms_per_room'] = X['total_bedrooms'] / X['total_rooms']\n",
    "        X['population_per_household'] = X['population'] / X['households']\n",
    "        X['rooms_per_household'] = X['total_rooms'] / X['households']\n",
    "        X['income_per_household'] = X['median_income'] / X['households']\n",
    "        X['income_per_bedroom'] = X['median_income'] / X['total_bedrooms']\n",
    "        X['income_per_room'] = X['median_income'] / X['total_rooms']\n",
    "        X['age_of_population'] = X['housing_median_age'] / X['population']\n",
    "        X['age_of_households'] = X['housing_median_age'] / X['households']\n",
    "        X['population_density'] = X['population'] / X['total_rooms']\n",
    "        X['bedrooms_per_population'] = X['total_bedrooms'] / X['population']\n",
    "        X['is_capped'] = X['median_house_value'] == 500000\n",
    "        \n",
    "\n",
    "        self.__get_distance_to_high_value_area(X)\n",
    "        \n",
    "        return X\n",
    "\n",
    "# Custom transformer to drop a column    \n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.column_name in X.columns:\n",
    "            X = X.drop(columns=[self.column_name])\n",
    "        return X\n",
    "    \n",
    "housing_data = pd.read_csv(\"../data/housing.csv\")\n",
    "train_set, test_set = train_test_split(housing_data, test_size=0.3, random_state=10)\n",
    "\n",
    "# Keep the original labels for training and testing\n",
    "y_train = train_set['median_house_value'].to_numpy()\n",
    "y_test = test_set['median_house_value'].to_numpy()\n",
    "\n",
    "num_attribs = train_set.columns.tolist()\n",
    "num_attribs.remove('ocean_proximity')\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "feature_eng = FeatureEngineering()\n",
    "feature_eng.fit(train_set)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('feature_eng', feature_eng),\n",
    "    ('drop_column', DropColumnTransformer('median_house_value')),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(train_set)\n",
    "X_test = pipeline.transform(test_set)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test a linear regression model\n",
    "\n",
    "To evaluate:\n",
    "1. The Root Mean Squared Error is used for the training error \n",
    "2. N-fold cross validation with RMSE is used, with 10 folds for the validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 65512.19687815971\n",
      "Linear Regression RMSE Scores: [65491.56395045 62939.19496873 64423.00782818 65956.13642558\n",
      " 67187.4882399  66054.65590843 64872.79467416 79491.74134393\n",
      " 65726.6694338  70087.43228025]\n",
      "Linear Regression RMSE Mean: 67223.06850533944\n",
      "Linear Regression RMSE Standard Deviation: 4457.011346877264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "lin_predictions = lin_reg.predict(X_train)\n",
    "\n",
    "lin_rmse = np.sqrt(mean_squared_error(y_train, lin_predictions))\n",
    "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "print('Linear Regression RMSE:', lin_rmse)\n",
    "print('Linear Regression RMSE Scores:', lin_rmse_scores)\n",
    "print('Linear Regression RMSE Mean:', lin_rmse_scores.mean())\n",
    "print('Linear Regression RMSE Standard Deviation:', lin_rmse_scores.std())    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. It seems that the model is underfitting as the error is around $67k\n",
    "2. We could try to:\n",
    "    * Use a more powerful model\n",
    "    * Add more features that give more signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0\n",
      "Scores: [66295.36308594 60796.25593123 68176.65528911 66208.60843192\n",
      " 70429.140568   69390.16185295 68109.15537166 65748.78157228\n",
      " 66863.53809333 64677.67522789]\n",
      "Mean: 66669.5335424307\n",
      "Standard Deviation: 2560.8818256409218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)\n",
    "tree_pred = tree_reg.predict(X_train)\n",
    "\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_train, tree_pred))\n",
    "scores = cross_val_score(tree_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"RMSE: {tree_rmse}\")\n",
    "print(f\"Scores: {tree_rmse_scores}\")\n",
    "print(f\"Mean: {tree_rmse_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {tree_rmse_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. Decision tree regressor is overfitting the data (Training RMSE = 0)\n",
    "2. Performance is a little bit better than the lineal regressor model when cross-validated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 17635.61412999737\n",
      "Scores: [46490.76984445 44447.25210052 47443.05010518 45810.53875402\n",
      " 48035.16763856 49020.16403656 46447.96852739 49081.04351026\n",
      " 46749.26444453 49525.37010026]\n",
      "Mean: 47305.05890617198\n",
      "Standard Deviation: 1538.98724340286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "forest_pred = forest_reg.predict(X_train)\n",
    "\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_train, forest_pred))\n",
    "scores = cross_val_score(forest_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"RMSE: {forest_rmse}\")\n",
    "print(f\"Scores: {forest_rmse_scores}\")\n",
    "print(f\"Mean: {forest_rmse_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {forest_rmse_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. The model stills overfit a lot but given that random forest is an ensemble mechanism, this helps to generalize and regularize so the overfitting is not as bad as the decision tree\n",
    "2. We could limit the 'max_depth', 'min_samples_split' and 'min_samples_leaf' to force the model to limit the complexity of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layered Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device=}')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size // 4)\n",
    "        self.fc4 = nn.Linear(hidden_size // 4, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Custom wrapper class to use PyTorch model with scikit-learn cross-validation\n",
    "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model, epochs=100, lr=0.01):\n",
    "        self.model = model.to(device)\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X).cpu().numpy()\n",
    "        return predictions.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 28235.45978784756\n",
      "Scores: [41286.50774169 39449.54959096 40942.04614358 44028.68295994\n",
      " 42819.39256196 43851.85429964 44263.38193735 44749.68769051\n",
      " 41582.43147122 44579.65542744]\n",
      "Mean: 42755.318982427954\n",
      "Standard Deviation: 1736.5787071620084\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 500\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "dropout_rate = 0.3\n",
    "epochs = 2000\n",
    "\n",
    "mlp = MLP(input_size, hidden_size, output_size, dropout_rate=dropout_rate)\n",
    "mlp_regressor = PyTorchRegressor(model=mlp, epochs=epochs, lr=learning_rate) \n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "mlp_predictions = mlp_regressor.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, mlp_predictions))\n",
    "scores = cross_val_score(mlp_regressor, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Scores: {rmse_scores}\")\n",
    "print(f\"Mean: {rmse_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {rmse_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. The MLP has slightly worse performance to the Random Forest regressor but the overfitting is not as bad as Random Forest.\n",
    "2. On GPU, the training time is the same as Random Forest on CPU, so this is a constrain.\n",
    "3. Hyperparameter optimization of this model was done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter optimization and Feature importance\n",
    "\n",
    "1. Do hyperparameter optimization for the Random Forest regressor\n",
    "2. Do Feature Importance to get an idea of the performance of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Best RMSE Score: 50057.95987145539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(estimator=forest_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print('Best Parameters:', best_params)\n",
    "print('Best RMSE Score:', best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RF with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 23514.40323603561\n",
      "Scores: [49932.96191154 47813.1644265  47700.73229024 49190.93573037\n",
      " 50845.7240867  51063.23020631 49971.94386957 50832.2712312\n",
      " 48926.01813995 52710.69831983]\n",
      "Mean: 49898.76802122211\n",
      "Standard Deviation: 1471.93663100848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "forest_reg = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=30\n",
    ")\n",
    "\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "forest_pred = forest_reg.predict(X_train)\n",
    "\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_train, forest_pred))\n",
    "\n",
    "scores = cross_val_score(forest_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"RMSE: {forest_rmse}\")\n",
    "print(f\"Scores: {forest_rmse_scores}\")\n",
    "print(f\"Mean: {forest_rmse_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {forest_rmse_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. After doing grid search on the forest regressor, the best loss is around 50k, slightly better than the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22812541578398277, 'median_income'),\n",
       " (0.11997758166974434, 'is_capped'),\n",
       " (0.10233567499491797, '<1H OCEAN'),\n",
       " (0.08133539991799771, 'age_of_households'),\n",
       " (0.054933949238275395, 'bedrooms_per_room'),\n",
       " (0.05354800585999428, 'population_per_household'),\n",
       " (0.050289366357560636, 'median_house_value'),\n",
       " (0.04585602004022396, 'longitude'),\n",
       " (0.04484695624952824, 'latitude'),\n",
       " (0.03749366274541716, 'population_density'),\n",
       " (0.0255555591421462, 'housing_median_age'),\n",
       " (0.021091486603471384, 'income_per_household'),\n",
       " (0.016056431348457394, 'income_per_room'),\n",
       " (0.015695218443333395, 'total_rooms'),\n",
       " (0.01509032965809341, 'rooms_per_household'),\n",
       " (0.014204469161580798, 'households'),\n",
       " (0.013827760406509734, 'income_per_bedroom'),\n",
       " (0.013417338286805466, 'age_of_population'),\n",
       " (0.011742629132884217, 'total_bedrooms'),\n",
       " (0.011529482925630325, 'distance_to_high_value_area'),\n",
       " (0.011164991205205428, 'population'),\n",
       " (0.008749217347609816, 'NEAR BAY'),\n",
       " (0.002191787030531861, 'ISLAND'),\n",
       " (0.0009013953783935048, 'bedrooms_per_population'),\n",
       " (3.9871071704584875e-05, 'INLAND')]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attributes = ['bedrooms_per_room', \n",
    "                    'population_per_household', \n",
    "                    'rooms_per_household', \n",
    "                    'income_per_household', \n",
    "                    'income_per_bedroom', \n",
    "                    'income_per_room', \n",
    "                    'age_of_population', \n",
    "                    'age_of_households', \n",
    "                    'population_density', \n",
    "                    'bedrooms_per_population', \n",
    "                    'is_capped', \n",
    "                    'distance_to_high_value_area']\n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "cat_encoder = pipeline.named_transformers_['cat']\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attributes + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "\n",
    "1. distance_to_high_value_area is not a very important feature, and to get this feature a clustering model has to be trained, so this feature is dropped. The hypothesis is that '<1H OCEAN>' is highly correlated with distance_to_high_value_area and there is redundancy in these 2 features\n",
    "2. A threshold of 0.01 is going to be use to filter out the least important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the MLP \n",
    "\n",
    "* New feature engineering pipeline to drop features and clustering functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14448, 20)\n",
      "(6192, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['bedrooms_per_room'] = X['total_bedrooms'] / X['total_rooms']\n",
    "        X['is_capped'] = X['median_house_value'] == 500000\n",
    "        X['population_per_household'] = X['population'] / X['households']\n",
    "        X['rooms_per_household'] = X['total_rooms'] / X['households']\n",
    "        X['income_per_household'] = X['median_income'] / X['households']\n",
    "        X['income_per_bedroom'] = X['median_income'] / X['total_bedrooms']\n",
    "        X['income_per_room'] = X['median_income'] / X['total_rooms']\n",
    "        X['age_of_population'] = X['housing_median_age'] / X['population']\n",
    "        X['age_of_households'] = X['housing_median_age'] / X['households']\n",
    "        X['population_density'] = X['population'] / X['total_rooms']\n",
    "\n",
    "        # Commented out as feature importance is low\n",
    "        # X['bedrooms_per_population'] = X['total_bedrooms'] / X['population']\n",
    "        # self.__get_distance_to_high_value_area(X) \n",
    "        \n",
    "        return X\n",
    "\n",
    "# Custom transformer to drop a column    \n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if type(X) == pd.DataFrame:\n",
    "            if self.column in X.columns:\n",
    "                X = X.drop(columns=[self.column])\n",
    "        elif type(X) == np.ndarray:\n",
    "            X = np.delete(X, self.column, axis=1)\n",
    "        return X\n",
    "    \n",
    "housing_data = pd.read_csv(\"../data/housing.csv\")\n",
    "train_set, test_set = train_test_split(housing_data, test_size=0.3, random_state=10)\n",
    "\n",
    "y_train = train_set['median_house_value'].to_numpy()\n",
    "y_test = test_set['median_house_value'].to_numpy()\n",
    "\n",
    "num_attribs = train_set.columns.tolist()\n",
    "num_attribs.remove('ocean_proximity')\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('feature_eng', FeatureEngineering()),\n",
    "    ('drop_column', DropColumnTransformer('median_house_value')),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(train_set)\n",
    "X_test = pipeline.transform(test_set)\n",
    "\n",
    "drop_column = DropColumnTransformer([19,21,22]) # Drop INLAND, ISLAND, NEAR BAY\n",
    "X_train = drop_column.transform(X_train)\n",
    "X_test = drop_column.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Training Dataset ------\n",
      "RMSE: 43322.5302452567\n",
      "Scores: [47825.38820605 45533.56754512 46574.76817572 47895.53130858\n",
      " 49635.92041949 49892.30977543 46562.36423438 51313.55822219\n",
      " 47513.7041949  50130.04620175]\n",
      "Mean: 48287.715828362496\n",
      "Standard Deviation: 1772.1537980024962\n"
     ]
    }
   ],
   "source": [
    "# Tuned hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 800\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "dropout_rate = 0.5\n",
    "epochs = 600\n",
    "\n",
    "mlp = MLP(input_size, hidden_size, output_size, dropout_rate=dropout_rate)\n",
    "mlp_regressor = PyTorchRegressor(model=mlp, epochs=epochs, lr=learning_rate) \n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "\n",
    "mlp_predictions = mlp_regressor.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, mlp_predictions))\n",
    "scores = cross_val_score(mlp_regressor, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"------ Training Dataset ------\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Scores: {rmse_scores}\")\n",
    "print(f\"Mean: {rmse_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {rmse_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note:\n",
    "* The feature engineering pipeline was reworked to remove the least important features and the performace improved a little bit\n",
    "* Hyperparameter optimization to the MLP was done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, min_samples_split=5, n_estimators=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, min_samples_split=5, n_estimators=30)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', min_samples_split=5, n_estimators=30)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=30\n",
    ")\n",
    "\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the MLP and RF with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Testing Dataset ------\n",
      "MLP RMSE: 51335.27222143574\n",
      "RF RMSE: 54955.7921407399\n"
     ]
    }
   ],
   "source": [
    "# Test dataset \n",
    "print(\"------ Testing Dataset ------\")\n",
    "mlp_predictions = mlp_regressor.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, mlp_predictions))\n",
    "print(f\"MLP RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "forest_predictions = forest_reg.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, forest_predictions))\n",
    "print(f\"RF RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. The MLP will be used for the e2e system. The reasons are:\n",
    "    * Better performance compared to RF optimized through Grid Search\n",
    "    * Scaling a NN is more straight forward (Data scaling, Model parallelism/sharding, distributed training/inference, quamtization, etc)\n",
    "    * As more data is available, the NN architecture can be arbitrarily more complex to fit the data.\n",
    "2. The MLP is slightly overfitting the training dataset because the test set loss is a little bit bigger. However the discrepancy is small and it is acceptable "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
